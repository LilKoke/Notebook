{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**サポートベクトルマシン（SVM）**\n\n* 線型分割可能（lineary separable)：直線で分割できる\n* マージンの大きい分類：クラスの間にできる限り太い道を通す分類\n* サポートベクトル（support vector)：道の際にあるインスタンス\n\nSVMはスケールの影響を受けやすい！\n\n* ハードマージン分類（hard margin classification) すべてのインスタンスが道に引っかからず、正しい側にいることを厳密に要求する分類\\\n    ➡線型分割できるときにしか使えない\\\n    ➡外れ値に敏感になりすぎる\n* ソフトマージン分類（soft margin classification) 道をできる限り太くしつつ、マージン違反（margin violation)を減らす\n\nCが小さい→マージン違反が多くなる、汎化性能は上がることもある\\\nSVMモデルが過学習している場合には、Cを小さくして正則化する\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn import datasets\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC\n\niris = datasets.load_iris()\nX=iris[\"data\"][:,(2,3)]\ny=(iris[\"target\"]==2).astype(np.float64)\n\nsvm_clf=Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\")),\n])\n\nsvm_clf.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T12:21:34.121349Z","iopub.execute_input":"2021-08-10T12:21:34.122101Z","iopub.status.idle":"2021-08-10T12:21:35.421276Z","shell.execute_reply.started":"2021-08-10T12:21:34.121981Z","shell.execute_reply":"2021-08-10T12:21:35.420217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_clf.predict([[5.5, 1.7]])#SVM分類器は各クラスの確率を出力しない","metadata":{"execution":{"iopub.status.busy":"2021-08-10T12:21:35.422652Z","iopub.execute_input":"2021-08-10T12:21:35.423003Z","iopub.status.idle":"2021-08-10T12:21:35.431015Z","shell.execute_reply.started":"2021-08-10T12:21:35.422972Z","shell.execute_reply":"2021-08-10T12:21:35.429935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.datasets import make_moons\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.svm import LinearSVC\nimport matplotlib.pyplot as plt\nX,y=make_moons(n_samples=100, noise=0.15)\npolynomial_svm_clf=Pipeline([\n    (\"poly_features\", PolynomialFeatures(degree=3)),\n    (\"scaler\", StandardScaler()),\n    (\"svm_clf\", LinearSVC(C=10, loss=\"hinge\"))\n])\n\npolynomial_svm_clf.fit(X,y)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T12:21:35.433055Z","iopub.execute_input":"2021-08-10T12:21:35.433333Z","iopub.status.idle":"2021-08-10T12:21:35.456324Z","shell.execute_reply.started":"2021-08-10T12:21:35.433307Z","shell.execute_reply":"2021-08-10T12:21:35.455278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predict = polynomial_svm_clf.predict(X)\nX0 = X[(y_predict==0)]\nX1 = X[(y_predict==1)]\nplt.scatter(X0[:,0],X0[:,1], label=\"X0\")\nplt.scatter(X1[:,0],X1[:,1], label=\"X0\")\nplt.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T12:21:35.458024Z","iopub.execute_input":"2021-08-10T12:21:35.458308Z","iopub.status.idle":"2021-08-10T12:21:35.671238Z","shell.execute_reply.started":"2021-08-10T12:21:35.458281Z","shell.execute_reply":"2021-08-10T12:21:35.670241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef plot_dataset(X, y, axes):\n    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\")\n    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\")\n    plt.axis(axes)\n    plt.grid(True, which='both')\n    plt.xlabel(r\"$x_1$\", fontsize=20)\n    plt.ylabel(r\"$x_2$\", fontsize=20, rotation=0)\n\nplot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\nplt.show()\ndef plot_predictions(clf, axes):\n    x0s = np.linspace(axes[0], axes[1], 100)\n    x1s = np.linspace(axes[2], axes[3], 100)\n    x0, x1 = np.meshgrid(x0s, x1s)\n    X = np.c_[x0.ravel(), x1.ravel()]\n    y_pred = clf.predict(X).reshape(x0.shape)\n    y_decision = clf.decision_function(X).reshape(x0.shape)\n    plt.contourf(x0, x1, y_pred, cmap=plt.cm.brg, alpha=0.2)\n    plt.contourf(x0, x1, y_decision, cmap=plt.cm.brg, alpha=0.1)\n\nplot_predictions(polynomial_svm_clf, [-1.5, 2.5, -1, 1.5])\nplot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T12:21:35.67243Z","iopub.execute_input":"2021-08-10T12:21:35.672738Z","iopub.status.idle":"2021-08-10T12:21:36.313102Z","shell.execute_reply.started":"2021-08-10T12:21:35.672713Z","shell.execute_reply":"2021-08-10T12:21:36.312025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\npoly_kernel_svm_clf=Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5))#degreeが多項式の次数、coefが高次多項式と低次多項式からどの程度の影響を認めるか\n])\n\npoly_kernel_svm_clf.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T12:21:36.314549Z","iopub.execute_input":"2021-08-10T12:21:36.315122Z","iopub.status.idle":"2021-08-10T12:21:36.328553Z","shell.execute_reply.started":"2021-08-10T12:21:36.315079Z","shell.execute_reply":"2021-08-10T12:21:36.327918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"poly100_kernel_svm_clf = Pipeline([\n    (\"scaler\",StandardScaler()),\n    (\"svm_clf\", SVC(kernel=\"poly\",degree=10, coef0=100, C=5))\n])\npoly100_kernel_svm_clf.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T12:21:36.329534Z","iopub.execute_input":"2021-08-10T12:21:36.329938Z","iopub.status.idle":"2021-08-10T12:21:36.357624Z","shell.execute_reply.started":"2021-08-10T12:21:36.329901Z","shell.execute_reply":"2021-08-10T12:21:36.356917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(11,4))\n\nplt.subplot(121)\nplot_predictions(poly_kernel_svm_clf, [-1.5,2.5,-1,1.5])\nplot_dataset(X,y,[-1.5,2.5,-1,1.5])\nplt.title(r\"$d=3, r=1, C=5$\", fontsize=18)\n\nplt.subplot(122)\nplot_predictions(poly100_kernel_svm_clf,[-1.5,2.5,-1,1.5])\nplot_dataset(X,y,[-1.5,2.5,-1,1.5])\nplt.title(r\"$d=10, r=100, C=5$\", fontsize=18)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T12:21:59.036161Z","iopub.execute_input":"2021-08-10T12:21:59.036525Z","iopub.status.idle":"2021-08-10T12:21:59.433375Z","shell.execute_reply.started":"2021-08-10T12:21:59.036497Z","shell.execute_reply":"2021-08-10T12:21:59.432433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 類似性関数（similarity function):個々のインスタンスが特定のランドマーク（landmark)にどの程度近いかを測定する関数\n* ガウス放射既定関数（RBF:radial basis function)：$\\phi_\\gamma(x,l) = \\exp(-\\gamma||x-l||^2)$","metadata":{}},{"cell_type":"code","source":"rbf_kernel_svm_clf = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"svm_clf\", SVC(kernel=\"rbf\", gamma=5, C=0.001))\n])\nrbf_kernel_svm_clf.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T12:22:15.752362Z","iopub.execute_input":"2021-08-10T12:22:15.752705Z","iopub.status.idle":"2021-08-10T12:22:15.765564Z","shell.execute_reply.started":"2021-08-10T12:22:15.752676Z","shell.execute_reply":"2021-08-10T12:22:15.76444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\n\ngamma1, gamma2 = 0.1, 5\nC1, C2 = 0.001, 1000\nhyperparams = (gamma1, C1), (gamma1, C2), (gamma2, C1), (gamma2, C2)\n\nsvm_clfs = []\nfor gamma, C in hyperparams:\n    rbf_kernel_svm_clf=Pipeline([\n        (\"scaler\", StandardScaler()),\n        (\"svm_clf\", SVC(kernel=\"rbf\", gamma=gamma, C=C))\n    ])\n    rbf_kernel_svm_clf.fit(X,y)\n    svm_clfs.append(rbf_kernel_svm_clf)\n\nplt.figure(figsize=(11,7))\n\nfor i, svm_clf in enumerate(svm_clfs):\n    plt.subplot(221+i)\n    plot_predictions(svm_clf, [-1.5, 2.5, -1, 1.5])\n    plot_dataset(X,y,[-1.5, 2.5, -1, 1.5])\n    gamm, C = hyperparams[i]\n    plt.title(r\"$\\gamma = {}, C= $\".format(gamma, C), fontsize=16)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T12:44:42.01261Z","iopub.execute_input":"2021-08-10T12:44:42.013022Z","iopub.status.idle":"2021-08-10T12:44:42.817094Z","shell.execute_reply.started":"2021-08-10T12:44:42.012982Z","shell.execute_reply":"2021-08-10T12:44:42.816372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"カーネルの選び方\\\n訓練セットが大きい場合や特徴量がたくさんあるとき➡線形カーネル\\\nそれほど大きくないとき➡ガウスRBFカーネルも試してもよい\\\nさらに余裕があるとき➡交差検証とグリッドサーチを使って他のカーネルを試す","metadata":{}},{"cell_type":"markdown","source":"SVMの考え方\n* 分類→マージン違反を減らしながら2つのクラスの間に最も太い道を通す\n* 回帰→マージン違反を減らしながら道の中に入るインスタンスができる限り多くなるようにする\n道の太さはハイパーパラメータεによって調整\\\nマージンに入る訓練インスタンスを増やしても、モデルの予測に影響はない→ε不感(ε-insensitive)","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import LinearSVR\n\nsvm_reg = LinearSVR(epsilon=1.5)\nsvm_reg.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T13:04:56.921224Z","iopub.execute_input":"2021-08-10T13:04:56.921573Z","iopub.status.idle":"2021-08-10T13:04:56.930941Z","shell.execute_reply.started":"2021-08-10T13:04:56.921545Z","shell.execute_reply":"2021-08-10T13:04:56.929782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVR\n\nsvm_poly_reg=SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1)\nsvm_poly_reg.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T13:04:58.898539Z","iopub.execute_input":"2021-08-10T13:04:58.898958Z","iopub.status.idle":"2021-08-10T13:04:58.924731Z","shell.execute_reply.started":"2021-08-10T13:04:58.898924Z","shell.execute_reply":"2021-08-10T13:04:58.923728Z"},"trusted":true},"execution_count":null,"outputs":[]}]}